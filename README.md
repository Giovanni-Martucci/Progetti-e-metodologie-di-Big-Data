# Big Data Projects and Methodologies

These projects make use of the primary Big Data methodologies, including:

- Hadoop: Hadoop is a framework for distributed storage and processing of large datasets across clusters of computers. It allows for parallel processing of data and fault tolerance, making it a popular choice for big data applications.

- Pyspark/ Spark: Spark is an open-source distributed computing system that is designed to be fast, flexible, and easy to use. It is built on top of the Hadoop Distributed File System (HDFS) and allows for in-memory processing of large datasets.

- LSH: Locality-Sensitive Hashing (LSH) is a technique used in data mining and machine learning to approximate similarity between data points. It is commonly used in applications such as nearest neighbor search and recommendation systems.

Together, these technologies form a powerful ecosystem for processing and analyzing big data, allowing for efficient storage, processing, and analysis of massive datasets.

